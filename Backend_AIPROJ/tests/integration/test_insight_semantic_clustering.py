"""
Tests for Semantic Theme Clustering Enhancement (Phase C Upgrade)

Tests verify:
1. Similar phrases are clustered together
2. Unrelated phrases are NOT clustered
3. Cross-document overlap detection via semantic similarity
4. Evidence links are present and bounded
5. Fallback behavior works gracefully
"""

import os
import sys
import tempfile
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Set test environment
os.environ["LLM_PROVIDER"] = "none"
os.environ["RAG_ENABLED"] = "true"

from app.tools.insights import aggregate_insights
from app.tools.insights.semantic_clustering import (
    get_embedding_function,
    cluster_themes_by_similarity,
    extract_evidence_links,
    create_semantic_clusters
)
from app.ingestion.integration import ingest_multi_file
from app.rag.retrieval.search import clear_test_documents


def test_similar_phrases_clustered():
    """Test that semantically similar phrases are grouped together."""
    print("\n" + "="*80)
    print("TEST 1: Similar Phrases Clustered Together")
    print("="*80)
    
    try:
        emb_func = get_embedding_function()
        
        if not emb_func:
            print("âš ï¸  SKIP: Embeddings not available (expected in minimal setup)")
            return True
        
        # Phrases that should cluster together
        phrases = [
            {
                "phrase": "Machine Learning",
                "frequency": 3,
                "document_ids": ["doc1", "doc2"]
            },
            {
                "phrase": "ML Algorithms",
                "frequency": 2,
                "document_ids": ["doc2", "doc3"]
            },
            {
                "phrase": "Artificial Intelligence",
                "frequency": 2,
                "document_ids": ["doc1"]
            },
            {
                "phrase": "AI Systems",
                "frequency": 1,
                "document_ids": ["doc3"]
            }
        ]
        
        print(f"\n[*] Clustering {len(phrases)} phrases...")
        clusters = cluster_themes_by_similarity(phrases, emb_func, similarity_threshold=0.35)
        
        print(f"\n[*] Results:")
        print(f"    Clusters created: {len(clusters)}")
        
        # Verify we got clusters
        has_clusters = len(clusters) > 0
        print(f"    Has clusters: {'âœ…' if has_clusters else 'âŒ'}")
        
        # Check if ML and ML Algorithms are grouped
        ml_cluster_found = False
        ai_cluster_found = False
        
        for cluster in clusters:
            members = [m.lower() for m in cluster['members']]
            print(f"\n    Cluster: {cluster['theme_label']}")
            print(f"      Members: {cluster['members']}")
            print(f"      Confidence: {cluster['confidence']:.3f}")
            
            if 'machine learning' in members or 'ml algorithms' in members:
                ml_cluster_found = True
            if 'artificial intelligence' in members or 'ai systems' in members:
                ai_cluster_found = True
        
        print(f"\n    ML concepts clustered: {'âœ…' if ml_cluster_found else 'âŒ'}")
        print(f"    AI concepts clustered: {'âœ…' if ai_cluster_found else 'âŒ'}")
        
        assert has_clusters, "Should create at least one cluster"
        
        print(f"\nâœ… TEST PASSED - Similar phrases successfully clustered")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_unrelated_phrases_not_clustered():
    """Test that unrelated phrases are kept separate."""
    print("\n" + "="*80)
    print("TEST 2: Unrelated Phrases NOT Clustered")
    print("="*80)
    
    try:
        emb_func = get_embedding_function()
        
        if not emb_func:
            print("âš ï¸  SKIP: Embeddings not available")
            return True
        
        # Phrases that should NOT cluster together
        phrases = [
            {
                "phrase": "Machine Learning",
                "frequency": 2,
                "document_ids": ["doc1"]
            },
            {
                "phrase": "Cooking Recipes",
                "frequency": 2,
                "document_ids": ["doc2"]
            },
            {
                "phrase": "Mountain Climbing",
                "frequency": 2,
                "document_ids": ["doc3"]
            }
        ]
        
        print(f"\n[*] Clustering {len(phrases)} unrelated phrases...")
        clusters = cluster_themes_by_similarity(phrases, emb_func, similarity_threshold=0.35)
        
        print(f"\n[*] Results:")
        print(f"    Clusters created: {len(clusters)}")
        
        # Each phrase should be its own cluster (or no clusters if they don't meet threshold)
        if clusters:
            all_separate = all(c['member_count'] == 1 for c in clusters)
            print(f"    All phrases separate: {'âœ…' if all_separate else 'âŒ'}")
        else:
            all_separate = True
            print(f"    No clusters formed (expected): âœ…")
        
        for cluster in clusters:
            print(f"\n    Cluster: {cluster['theme_label']}")
            print(f"      Members: {cluster['members']}")
            print(f"      Confidence: {cluster['confidence']:.3f}")
        
        print(f"\nâœ… TEST PASSED - Unrelated phrases kept separate")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_cross_document_overlap_detection():
    """Test semantic clustering detects cross-document patterns."""
    print("\n" + "="*80)
    print("TEST 3: Cross-Document Overlap Detection")
    print("="*80)
    
    docs_to_cleanup = []
    
    try:
        # Create test documents with similar concepts expressed differently
        doc1_content = """Deep Learning Fundamentals
        
Neural networks are the foundation of modern AI.
Deep learning uses multiple layers for pattern recognition.
Training requires large datasets and computational power."""
        
        doc2_content = """Artificial Neural Networks
        
Artificial neural networks mimic biological brain structure.
Multi-layer networks enable complex pattern detection.
Large training datasets improve model accuracy."""
        
        print("\n[*] Cleaning test documents...")
        clear_test_documents(source_pattern="test_semantic")
        
        print(f"\n[*] Ingesting 2 test documents...")
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            f.write(doc1_content)
            docs_to_cleanup.append(f.name)
        
        result1 = ingest_multi_file(
            file_path=docs_to_cleanup[0],
            source="test_semantic_doc1.txt",
            normalize=True,
            exists_policy="overwrite"
        )
        doc1_id = result1['document_id']
        print(f"    Document 1: {doc1_id}")
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            f.write(doc2_content)
            docs_to_cleanup.append(f.name)
        
        result2 = ingest_multi_file(
            file_path=docs_to_cleanup[1],
            source="test_semantic_doc2.txt",
            normalize=True,
            exists_policy="overwrite"
        )
        doc2_id = result2['document_id']
        print(f"    Document 2: {doc2_id}")
        
        # Aggregate with semantic clustering
        print(f"\n[*] Running aggregation with semantic clustering...")
        result, telemetry = aggregate_insights(
            document_ids=[doc1_id, doc2_id],
            mode="extractive",
            max_chunks=5
        )
        
        print(f"\n[*] Verification:")
        print(f"    Semantic clustering used: {'âœ…' if telemetry.get('semantic_clustering_used') else 'âŒ'}")
        print(f"    Cluster count: {telemetry.get('cluster_count', 0)}")
        print(f"    Avg confidence: {telemetry.get('avg_cluster_confidence', 0):.3f}")
        
        # Check for semantic clusters
        insights = result.get('aggregated_insights', {})
        has_semantic_clusters = 'semantic_clusters' in insights
        print(f"    Has semantic_clusters field: {'âœ…' if has_semantic_clusters else 'âŒ'}")
        
        if has_semantic_clusters:
            clusters = insights['semantic_clusters']
            print(f"    Number of clusters: {len(clusters)}")
            
            # Look for neural network / deep learning related clusters
            for cluster in clusters[:5]:
                print(f"\n    Cluster: {cluster['theme_label']}")
                print(f"      Members: {cluster.get('member_count', 0)}")
                print(f"      Docs involved: {len(cluster.get('documents_involved', []))}")
                print(f"      Confidence: {cluster['confidence']:.3f}")
        
        # Check evidence links
        has_evidence = insights.get('evidence_links', False)
        print(f"\n    Evidence links available: {'âœ…' if has_evidence else 'âŒ'}")
        
        print(f"\nâœ… TEST PASSED - Cross-document overlap detection working")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        for doc_path in docs_to_cleanup:
            if os.path.exists(doc_path):
                os.unlink(doc_path)


def test_evidence_links_present():
    """Test that evidence links are present and properly bounded."""
    print("\n" + "="*80)
    print("TEST 4: Evidence Links Present and Bounded")
    print("="*80)
    
    try:
        emb_func = get_embedding_function()
        
        if not emb_func:
            print("âš ï¸  SKIP: Embeddings not available")
            return True
        
        # Create mock summaries
        summaries = [
            {
                "document_id": "doc1",
                "summary": "Machine learning algorithms process data to find patterns. Neural networks are particularly effective for complex tasks.",
                "confidence": 0.85
            },
            {
                "document_id": "doc2",
                "summary": "Deep learning uses neural architectures with multiple layers. Training requires substantial computational resources.",
                "confidence": 0.90
            }
        ]
        
        theme = "Machine Learning"
        
        print(f"\n[*] Extracting evidence for theme: '{theme}'")
        evidence = extract_evidence_links(summaries, theme, emb_func, max_evidence=3)
        
        print(f"\n[*] Results:")
        print(f"    Evidence items found: {len(evidence)}")
        
        has_evidence = len(evidence) > 0
        print(f"    Has evidence: {'âœ…' if has_evidence else 'âŒ'}")
        
        # Check evidence structure and bounds
        for i, ev in enumerate(evidence, 1):
            print(f"\n    Evidence {i}:")
            print(f"      Document: {ev.get('document_id', 'N/A')}")
            print(f"      Similarity: {ev.get('similarity', 0):.3f}")
            print(f"      Preview length: {len(ev.get('text_preview', ''))}")
            print(f"      Preview: {ev.get('text_preview', '')[:100]}...")
            
            # Verify bounded length (should be <= 200 chars + "...")
            preview_len = len(ev.get('text_preview', ''))
            is_bounded = preview_len <= 203  # 200 + "..." = 203
            print(f"      Length bounded: {'âœ…' if is_bounded else 'âŒ'}")
            
            assert is_bounded, f"Evidence preview too long: {preview_len} chars"
        
        # Verify max_evidence limit respected
        is_limited = len(evidence) <= 3
        print(f"\n    Evidence count limited to max: {'âœ…' if is_limited else 'âŒ'}")
        
        print(f"\nâœ… TEST PASSED - Evidence links properly formatted and bounded")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_fallback_behavior():
    """Test that fallback works gracefully when embeddings unavailable."""
    print("\n" + "="*80)
    print("TEST 5: Fallback Behavior (Graceful Degradation)")
    print("="*80)
    
    try:
        # Simulate embedding unavailability by passing None
        themes = [
            {"phrase": "Machine Learning", "frequency": 2, "document_ids": ["doc1"]},
            {"phrase": "Neural Networks", "frequency": 1, "document_ids": ["doc2"]}
        ]
        overlaps = []
        summaries = []
        
        print(f"\n[*] Testing with no embedding function...")
        clusters, metadata = create_semantic_clusters(themes, overlaps, summaries)
        
        print(f"\n[*] Results:")
        print(f"    Clusters returned: {len(clusters)}")
        print(f"    Semantic clustering used: {metadata['semantic_clustering_used']}")
        print(f"    Fallback reason: {metadata.get('fallback_reason', 'N/A')}")
        
        # Should gracefully return empty clusters with metadata
        graceful_fallback = not metadata['semantic_clustering_used']
        has_fallback_reason = metadata.get('fallback_reason') is not None
        no_crash = True  # If we got here, no crash occurred
        
        print(f"    Graceful fallback: {'âœ…' if graceful_fallback else 'âŒ'}")
        print(f"    Has fallback reason: {'âœ…' if has_fallback_reason else 'âŒ'}")
        print(f"    No crash: {'âœ…' if no_crash else 'âŒ'}")
        
        assert not metadata['semantic_clustering_used'], "Should indicate clustering not used"
        assert metadata.get('fallback_reason'), "Should provide fallback reason"
        
        print(f"\nâœ… TEST PASSED - Fallback behavior works gracefully")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_end_to_end_with_clustering():
    """Test full end-to-end aggregation with semantic clustering."""
    print("\n" + "="*80)
    print("TEST 6: End-to-End Aggregation with Semantic Clustering")
    print("="*80)
    
    docs_to_cleanup = []
    
    try:
        # Create test documents with related concepts
        doc1_content = """Machine Learning Overview
        
Machine learning enables computers to learn from data.
Supervised learning uses labeled datasets for training.
Neural networks can recognize complex patterns."""
        
        doc2_content = """AI Technologies
        
Artificial intelligence transforms modern computing.
ML algorithms discover patterns automatically.
Deep neural architectures power modern AI systems."""
        
        doc3_content = """Data Science Methods
        
Data analysis reveals insights from information.
Statistical models predict future trends.
Machine learning automates pattern discovery."""
        
        print("\n[*] Cleaning test documents...")
        clear_test_documents(source_pattern="test_e2e")
        
        print(f"\n[*] Ingesting 3 test documents...")
        
        for i, content in enumerate([doc1_content, doc2_content, doc3_content], 1):
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
                f.write(content)
                docs_to_cleanup.append(f.name)
            
            result = ingest_multi_file(
                file_path=docs_to_cleanup[-1],
                source=f"test_e2e_doc{i}.txt",
                normalize=True,
                exists_policy="overwrite"
            )
            print(f"    Document {i}: {result['document_id']}")
        
        doc_ids = [
            ingest_multi_file(docs_to_cleanup[0], source="test_e2e_doc1.txt", normalize=True, exists_policy="overwrite")['document_id'],
            ingest_multi_file(docs_to_cleanup[1], source="test_e2e_doc2.txt", normalize=True, exists_policy="overwrite")['document_id'],
            ingest_multi_file(docs_to_cleanup[2], source="test_e2e_doc3.txt", normalize=True, exists_policy="overwrite")['document_id']
        ]
        
        # Run full aggregation
        print(f"\n[*] Running full aggregation with semantic clustering...")
        result, telemetry = aggregate_insights(
            document_ids=doc_ids,
            mode="extractive",
            max_chunks=5
        )
        
        print(f"\n[*] Aggregation Results:")
        print(f"    Documents processed: {telemetry['files_processed']}")
        print(f"    Semantic clustering used: {telemetry.get('semantic_clustering_used', False)}")
        print(f"    Cluster count: {telemetry.get('cluster_count', 0)}")
        
        insights = result.get('aggregated_insights', {})
        
        # Verify all expected fields present (backward compatibility)
        expected_fields = ['themes', 'overlaps', 'differences', 'entities', 'risk_signals']
        all_present = all(field in insights for field in expected_fields)
        print(f"    All original fields present: {'âœ…' if all_present else 'âŒ'}")
        
        # Check new fields (non-breaking additions)
        has_semantic = 'semantic_clusters' in insights
        has_evidence_flag = 'evidence_links' in insights
        
        print(f"    Has semantic_clusters: {'âœ…' if has_semantic else 'âš ï¸  (optional)'}")
        print(f"    Has evidence_links flag: {'âœ…' if has_evidence_flag else 'âš ï¸  (optional)'}")
        
        # If clustering succeeded, verify structure
        if has_semantic and insights['semantic_clusters']:
            print(f"\n[*] Semantic Cluster Details:")
            for i, cluster in enumerate(insights['semantic_clusters'][:3], 1):
                print(f"\n    Cluster {i}: {cluster['theme_label']}")
                print(f"      Members: {cluster.get('member_count', 0)}")
                print(f"      Confidence: {cluster['confidence']:.3f}")
                print(f"      Evidence count: {cluster.get('evidence_count', 0)}")
                
                # Verify cluster structure
                required_cluster_fields = ['theme_label', 'members', 'documents_involved', 'confidence']
                cluster_valid = all(field in cluster for field in required_cluster_fields)
                print(f"      Valid structure: {'âœ…' if cluster_valid else 'âŒ'}")
        
        # Verify telemetry includes new fields
        new_telemetry_fields = ['semantic_clustering_used', 'cluster_count']
        telemetry_complete = all(field in telemetry for field in new_telemetry_fields)
        print(f"\n    Telemetry includes new fields: {'âœ…' if telemetry_complete else 'âŒ'}")
        
        assert all_present, "Original fields must be present (backward compatibility)"
        
        print(f"\nâœ… TEST PASSED - End-to-end aggregation with clustering successful")
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        for doc_path in docs_to_cleanup:
            if os.path.exists(doc_path):
                os.unlink(doc_path)


def run_all_tests():
    """Run all semantic clustering tests."""
    print("\n" + "="*80)
    print("PHASE C UPGRADE TEST SUITE - Semantic Clustering")
    print("="*80)
    
    tests = [
        ("Similar Phrases Clustered", test_similar_phrases_clustered),
        ("Unrelated Phrases NOT Clustered", test_unrelated_phrases_not_clustered),
        ("Cross-Document Overlap Detection", test_cross_document_overlap_detection),
        ("Evidence Links Present and Bounded", test_evidence_links_present),
        ("Fallback Behavior", test_fallback_behavior),
        ("End-to-End with Clustering", test_end_to_end_with_clustering),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, "PASSED" if success else "FAILED"))
        except Exception as e:
            print(f"\nâŒ TEST EXCEPTION: {test_name}")
            print(f"   Error: {str(e)}")
            import traceback
            traceback.print_exc()
            results.append((test_name, f"FAILED: {str(e)[:50]}"))
    
    # Summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)
    
    for test_name, status in results:
        if "SKIP" in status:
            status_icon = "âš ï¸ "
        elif status == "PASSED":
            status_icon = "âœ…"
        else:
            status_icon = "âŒ"
        print(f"{status_icon} {test_name}: {status}")
    
    passed_count = sum(1 for _, status in results if status == "PASSED")
    skipped_count = sum(1 for _, status in results if "SKIP" in status)
    total_count = len(results)
    
    print(f"\nğŸ“Š Overall: {passed_count}/{total_count} tests passed")
    if skipped_count > 0:
        print(f"âš ï¸  {skipped_count} tests skipped (embeddings not available)")
    
    if passed_count == total_count:
        print("ğŸ‰ All tests PASSED!")
        return True
    elif passed_count + skipped_count == total_count:
        print("âœ… All runnable tests PASSED (some skipped)")
        return True
    else:
        print("âš ï¸  Some tests FAILED")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
